#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Streamlitæ¼”ç¤ºåº”ç”¨
å¤šæ ‡ç­¾æ™ºèƒ½å®¡æ ¸ç³»ç»Ÿçš„äº¤äº’å¼ç•Œé¢
"""

import os
import re
import csv
from datetime import datetime
import pandas as pd
import numpy as np
import torch
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification


# æ ‡ç­¾åç§°
LABEL_NAMES = ['porn', 'abuse', 'region', 'gender', 'race', 'occupation']
LABEL_NAMES_CN = {
    'porn': 'è‰²æƒ…',
    'abuse': 'è¾±éª‚',
    'region': 'åœ°åŸŸæ­§è§†',
    'gender': 'æ€§åˆ«æ­§è§†',
    'race': 'ç§æ—æ­§è§†',
    'occupation': 'èŒä¸šæ­§è§†'
}


@st.cache_resource
def load_model(model_path='outputs/best_model'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    if not os.path.exists(model_path):
        st.error(f"æ¨¡å‹æœªæ‰¾åˆ°: {model_path}")
        st.info("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python train_multilabel.py")
        return None, None
    
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    model.eval()
    
    return tokenizer, model


def apply_rules(text):
    """åº”ç”¨ç®€å•è§„åˆ™æ£€æµ‹"""
    matched_rules = []
    rule_scores = {label: 0.0 for label in LABEL_NAMES}
    
    # URLæ£€æµ‹
    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
    if re.search(url_pattern, text):
        matched_rules.append("æ£€æµ‹åˆ°URLé“¾æ¥")
        rule_scores['abuse'] += 0.1  # å¯èƒ½æ˜¯åƒåœ¾ä¿¡æ¯
    
    # æ‰‹æœºå·æ£€æµ‹
    phone_pattern = r'1[3-9]\d{9}'
    if re.search(phone_pattern, text):
        matched_rules.append("æ£€æµ‹åˆ°æ‰‹æœºå·")
        rule_scores['abuse'] += 0.2  # å¯èƒ½æ˜¯å¹¿å‘Š/åƒåœ¾ä¿¡æ¯
    
    # é‡å¤å­—ç¬¦æ£€æµ‹ï¼ˆçŒæ°´ï¼‰
    repeat_pattern = r'(.)\1{4,}'  # 5ä¸ªæˆ–æ›´å¤šç›¸åŒå­—ç¬¦
    if re.search(repeat_pattern, text):
        matched_rules.append("æ£€æµ‹åˆ°é‡å¤å­—ç¬¦ï¼ˆå¯èƒ½çŒæ°´ï¼‰")
        rule_scores['abuse'] += 0.15
    
    # çŸ­æ–‡æœ¬å¤§é‡é‡å¤å­—ç¬¦
    if len(text) < 20 and len(set(text)) < 5:
        matched_rules.append("æ–‡æœ¬è¿‡äºç®€å•/é‡å¤")
        rule_scores['abuse'] += 0.1
    
    # æ£€æµ‹è‰²æƒ…å…³é”®è¯ï¼ˆç®€å•ç¤ºä¾‹ï¼‰
    porn_keywords = ['åšçˆ±', 'æ€§äº¤', 'è‰²æƒ…', 'é»„è‰²', 'è£¸ä½“', 'æ€§çˆ±', 'æ·«']
    for keyword in porn_keywords:
        if keyword in text:
            matched_rules.append(f"æ£€æµ‹åˆ°æ•æ„Ÿè¯: {keyword}")
            rule_scores['porn'] += 0.3
            break
    
    # æ£€æµ‹è¾±éª‚å…³é”®è¯
    abuse_keywords = ['å‚»é€¼', 'å‚»é€¼', 'å»æ­»', 'åƒåœ¾', 'åºŸç‰©', 'è ¢è´§', 'ç™½ç—´']
    for keyword in abuse_keywords:
        if keyword in text:
            matched_rules.append(f"æ£€æµ‹åˆ°è¾±éª‚è¯: {keyword}")
            rule_scores['abuse'] += 0.3
            break
    
    return matched_rules, rule_scores


def predict_single(text, tokenizer, model, thresholds):
    """å¯¹å•æ¡æ–‡æœ¬è¿›è¡Œé¢„æµ‹"""
    # åº”ç”¨è§„åˆ™
    matched_rules, rule_scores = apply_rules(text)
    
    # æ¨¡å‹é¢„æµ‹
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=150)
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.sigmoid(logits).squeeze().numpy()
    
    # èåˆè§„åˆ™åˆ†æ•°ï¼ˆç®€å•åŠ æƒï¼‰
    fused_probs = {}
    decisions = {}
    
    for i, label in enumerate(LABEL_NAMES):
        # èåˆæ¨¡å‹æ¦‚ç‡å’Œè§„åˆ™åˆ†æ•°
        base_prob = float(probs[i])
        rule_boost = rule_scores[label]
        fused_prob = min(1.0, base_prob + rule_boost)
        fused_probs[label] = fused_prob
        
        # æ ¹æ®é˜ˆå€¼åˆ¤å®š
        threshold = thresholds[label]
        decisions[label] = fused_prob >= threshold
    
    return probs, fused_probs, decisions, matched_rules


def log_prediction(text, probs, decisions, matched_rules):
    """è®°å½•é¢„æµ‹ç»“æœåˆ°æ—¥å¿—"""
    os.makedirs('logs', exist_ok=True)
    log_path = 'logs/pred_log.csv'
    
    # å‡†å¤‡æ—¥å¿—è®°å½•
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_entry = {
        'timestamp': timestamp,
        'text': text[:100],  # é™åˆ¶æ–‡æœ¬é•¿åº¦
        'matched_rules': '; '.join(matched_rules) if matched_rules else 'None',
    }
    
    # æ·»åŠ æ¦‚ç‡å’Œå†³ç­–
    for label in LABEL_NAMES:
        log_entry[f'prob_{label}'] = f"{probs[label]:.4f}"
        log_entry[f'decision_{label}'] = 'YES' if decisions[label] else 'NO'
    
    # å†™å…¥CSV
    file_exists = os.path.exists(log_path)
    with open(log_path, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=log_entry.keys())
        if not file_exists:
            writer.writeheader()
        writer.writerow(log_entry)


def main():
    """ä¸»åº”ç”¨"""
    st.set_page_config(
        page_title="å¤šæ ‡ç­¾æ™ºèƒ½å®¡æ ¸ç³»ç»Ÿ",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    st.title("ğŸ” ç”¨æˆ·è¯„è®ºå¤šæ ‡ç­¾æ™ºèƒ½å®¡æ ¸ç³»ç»Ÿ")
    st.markdown("åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„ä¸­æ–‡è¯„è®ºå¤šæ ‡ç­¾åˆ†ç±»ç³»ç»Ÿ")
    
    # åŠ è½½æ¨¡å‹
    with st.spinner("æ­£åœ¨åŠ è½½æ¨¡å‹..."):
        tokenizer, model = load_model()
    
    if tokenizer is None or model is None:
        st.stop()
    
    st.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    
    # ä¾§è¾¹æ ï¼šé˜ˆå€¼è®¾ç½®
    st.sidebar.header("âš™ï¸ é˜ˆå€¼è®¾ç½®")
    
    # å…¨å±€é˜ˆå€¼
    global_threshold = st.sidebar.slider(
        "å…¨å±€é˜ˆå€¼",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="åº”ç”¨åˆ°æ‰€æœ‰æ ‡ç­¾çš„åŸºç¡€é˜ˆå€¼"
    )
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("å„æ ‡ç­¾é˜ˆå€¼å¾®è°ƒ")
    
    # æ¯ä¸ªæ ‡ç­¾çš„é˜ˆå€¼
    thresholds = {}
    for label in LABEL_NAMES:
        label_cn = LABEL_NAMES_CN[label]
        thresholds[label] = st.sidebar.slider(
            label_cn,
            min_value=0.0,
            max_value=1.0,
            value=global_threshold,
            step=0.05,
            key=f"threshold_{label}"
        )
    
    # ä¸»ç•Œé¢ï¼šé€‰é¡¹å¡
    tab1, tab2 = st.tabs(["ğŸ“ å•æ¡é¢„æµ‹", "ğŸ“Š æ‰¹é‡é¢„æµ‹"])
    
    # Tab 1: å•æ¡é¢„æµ‹
    with tab1:
        st.header("å•æ¡æ–‡æœ¬å®¡æ ¸")
        
        # æ–‡æœ¬è¾“å…¥
        input_text = st.text_area(
            "è¯·è¾“å…¥å¾…å®¡æ ¸çš„æ–‡æœ¬ï¼š",
            height=100,
            placeholder="ä¾‹å¦‚ï¼šè¿™æ˜¯ä¸€æ¡æµ‹è¯•è¯„è®º..."
        )
        
        if st.button("ğŸ” å¼€å§‹å®¡æ ¸", type="primary"):
            if not input_text.strip():
                st.warning("è¯·è¾“å…¥æ–‡æœ¬ï¼")
            else:
                with st.spinner("æ­£åœ¨åˆ†æ..."):
                    # é¢„æµ‹
                    probs, fused_probs, decisions, matched_rules = predict_single(
                        input_text, tokenizer, model, thresholds
                    )
                    
                    # è®°å½•æ—¥å¿—
                    log_prediction(input_text, fused_probs, decisions, matched_rules)
                
                # æ˜¾ç¤ºç»“æœ
                st.subheader("ğŸ“‹ å®¡æ ¸ç»“æœ")
                
                # è§„åˆ™åŒ¹é…
                if matched_rules:
                    st.warning("âš ï¸ è§„åˆ™åŒ¹é…ç»“æœï¼š")
                    for rule in matched_rules:
                        st.write(f"- {rule}")
                else:
                    st.info("âœ“ æœªåŒ¹é…åˆ°ç‰¹å®šè§„åˆ™")
                
                st.markdown("---")
                
                # æ ‡ç­¾é¢„æµ‹ç»“æœ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ¯ æ¨¡å‹é¢„æµ‹æ¦‚ç‡")
                    for label in LABEL_NAMES:
                        label_cn = LABEL_NAMES_CN[label]
                        prob = probs[label]
                        st.progress(prob, text=f"{label_cn}: {prob:.2%}")
                
                with col2:
                    st.subheader("âœ… èåˆååˆ¤å®šç»“æœ")
                    for label in LABEL_NAMES:
                        label_cn = LABEL_NAMES_CN[label]
                        fused_prob = fused_probs[label]
                        decision = decisions[label]
                        
                        if decision:
                            st.error(f"ğŸš« {label_cn}: {fused_prob:.2%} (è§¦å‘)")
                        else:
                            st.success(f"âœ“ {label_cn}: {fused_prob:.2%} (æ­£å¸¸)")
                
                # ç»¼åˆåˆ¤å®š
                st.markdown("---")
                if any(decisions.values()):
                    st.error("â›” **ç»¼åˆåˆ¤å®šï¼šè¯¥å†…å®¹å­˜åœ¨è¿è§„é£é™©ï¼Œå»ºè®®å®¡æ ¸æˆ–å±è”½**")
                else:
                    st.success("âœ… **ç»¼åˆåˆ¤å®šï¼šè¯¥å†…å®¹æœªå‘ç°æ˜æ˜¾è¿è§„**")
    
    # Tab 2: æ‰¹é‡é¢„æµ‹
    with tab2:
        st.header("æ‰¹é‡æ–‡æœ¬å®¡æ ¸")
        
        st.markdown("""
        ä¸Šä¼ åŒ…å« `text` åˆ—çš„ CSV æ–‡ä»¶è¿›è¡Œæ‰¹é‡å®¡æ ¸ã€‚
        ç³»ç»Ÿå°†ä¸ºæ¯æ¡æ–‡æœ¬ç”Ÿæˆé¢„æµ‹ç»“æœï¼Œå¹¶æä¾›ä¸‹è½½ã€‚
        """)
        
        uploaded_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type=['csv'])
        
        if uploaded_file is not None:
            # è¯»å–æ–‡ä»¶
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            
            if 'text' not in df.columns:
                st.error("CSVæ–‡ä»¶å¿…é¡»åŒ…å« 'text' åˆ—ï¼")
            else:
                st.info(f"å·²åŠ è½½ {len(df)} æ¡æ–‡æœ¬")
                st.dataframe(df.head())
                
                if st.button("ğŸš€ å¼€å§‹æ‰¹é‡å®¡æ ¸", type="primary"):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = []
                    
                    for idx, row in df.iterrows():
                        text = str(row['text'])
                        
                        # é¢„æµ‹
                        probs, fused_probs, decisions, matched_rules = predict_single(
                            text, tokenizer, model, thresholds
                        )
                        
                        # æ„å»ºç»“æœè¡Œ
                        result_row = {'text': text}
                        
                        # æ·»åŠ æ¯ä¸ªæ ‡ç­¾çš„æ¦‚ç‡å’Œåˆ¤å®š
                        for label in LABEL_NAMES:
                            result_row[f'{label}_prob'] = fused_probs[label]
                            result_row[f'{label}_decision'] = 'YES' if decisions[label] else 'NO'
                        
                        result_row['matched_rules'] = '; '.join(matched_rules) if matched_rules else 'None'
                        result_row['has_violation'] = any(decisions.values())
                        
                        results.append(result_row)
                        
                        # æ›´æ–°è¿›åº¦
                        progress = (idx + 1) / len(df)
                        progress_bar.progress(progress)
                        status_text.text(f"å¤„ç†è¿›åº¦: {idx + 1}/{len(df)}")
                    
                    # è½¬æ¢ä¸ºDataFrame
                    result_df = pd.DataFrame(results)
                    
                    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
                    st.success("âœ… æ‰¹é‡å®¡æ ¸å®Œæˆï¼")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ€»æ–‡æœ¬æ•°", len(result_df))
                    with col2:
                        violation_count = result_df['has_violation'].sum()
                        st.metric("è¿è§„æ–‡æœ¬æ•°", violation_count)
                    with col3:
                        violation_rate = violation_count / len(result_df) * 100
                        st.metric("è¿è§„ç‡", f"{violation_rate:.1f}%")
                    
                    # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                    st.subheader("ç»“æœé¢„è§ˆ")
                    st.dataframe(result_df.head(20))
                    
                    # æä¾›ä¸‹è½½
                    csv_output = result_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å®Œæ•´ç»“æœ (CSV)",
                        data=csv_output,
                        file_name=f"audit_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
    
    # åº•éƒ¨ä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.info("""
    **ä½¿ç”¨è¯´æ˜ï¼š**
    1. è°ƒæ•´å„æ ‡ç­¾çš„é˜ˆå€¼
    2. åœ¨"å•æ¡é¢„æµ‹"ä¸­è¾“å…¥æ–‡æœ¬è¿›è¡Œå®¡æ ¸
    3. åœ¨"æ‰¹é‡é¢„æµ‹"ä¸­ä¸Šä¼ CSVæ–‡ä»¶
    4. æ‰€æœ‰å•æ¡é¢„æµ‹ä¼šè®°å½•åˆ° logs/pred_log.csv
    """)


if __name__ == '__main__':
    main()
